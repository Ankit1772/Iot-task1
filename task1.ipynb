{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRIP February 2022 - The Sparks Foundation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IoT and Computer Vision Internship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1- Optical Character Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author - Ankit Kumar Singh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract as pyt              #pytesseract is used to work with Tesseract-OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyt.pytesseract.tesseract_cmd = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "img = cv2.imread('test_img.png')\n",
    "cv2.imshow(\"image\",img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# changing image from BGR to RGB colorspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '1', '0', '0', '0', '0', '0', '0', '745', '350', '-1']\n",
      "['2', '1', '1', '0', '0', '0', '94', '50', '556', '137', '-1']\n",
      "['3', '1', '1', '1', '0', '0', '94', '50', '556', '137', '-1']\n",
      "['4', '1', '1', '1', '1', '0', '94', '50', '556', '32', '-1']\n",
      "['5', '1', '1', '1', '1', '1', '94', '50', '101', '27', '96.055183', 'This']\n",
      "['5', '1', '1', '1', '1', '2', '223', '50', '36', '27', '96.055183', 'is']\n",
      "['5', '1', '1', '1', '1', '3', '286', '58', '26', '19', '96.148827', 'a']\n",
      "['5', '1', '1', '1', '1', '4', '339', '52', '169', '30', '96.246635', 'sample']\n",
      "['5', '1', '1', '1', '1', '5', '536', '53', '114', '24', '96.066895', 'text.']\n",
      "['4', '1', '1', '1', '2', '0', '234', '150', '273', '37', '-1']\n",
      "['5', '1', '1', '1', '2', '1', '234', '150', '196', '37', '80.070824', 'Difficult.']\n",
      "['5', '1', '1', '1', '2', '2', '342', '146', '46', '45', '81.958084', 'font']\n",
      "['5', '1', '1', '1', '2', '3', '398', '146', '39', '45', '78.060036', 'for']\n",
      "['5', '1', '1', '1', '2', '4', '444', '151', '63', '26', '96.606430', 'OCR.']\n",
      "['2', '1', '2', '0', '0', '0', '163', '275', '417', '37', '-1']\n",
      "['3', '1', '2', '1', '0', '0', '163', '275', '417', '37', '-1']\n",
      "['4', '1', '2', '1', '1', '0', '163', '275', '417', '37', '-1']\n",
      "['5', '1', '2', '1', '1', '1', '163', '275', '98', '37', '93.127190', 'Sample']\n",
      "['5', '1', '2', '1', '1', '2', '271', '275', '117', '30', '0.000000', 'Number-']\n",
      "['5', '1', '2', '1', '1', '3', '394', '275', '186', '30', '0.000000', '0987654321']\n"
     ]
    }
   ],
   "source": [
    "img_h, img_w, _ = img.shape\n",
    "boxes = pyt.image_to_data(img)                          #save details of the image in string \"boxes\"\n",
    "# print(boxes)\n",
    "# The structure of boxes is like:\n",
    "# [   0          1           2           3           4          5         6       7       8        9        10       11 ]\n",
    "# ['level', 'page_num', 'block_num', 'par_num', 'line_num', 'word_num', 'left', 'top', 'width', 'height', 'conf', 'text']\n",
    "\n",
    "for i, a in enumerate(boxes.splitlines()):\n",
    "    if i != 0:                                 #the first row of boxes is ignored i.e the heading row\n",
    "        a = a.split()\n",
    "        print(a)\n",
    "        if len(a) == 12:                       #only these rows contain the actual words present in the image\n",
    "            x, y, w, h = int(a[6]), int(a[7]), int(a[8]), int(a[9])    #saving coordinates and width and height for the rectangles\n",
    "            cv2.rectangle(img, (x, y), (w + x, h + y), (0, 0, 255), 1) #creating rectangle around words\n",
    "            cv2.putText(img, a[11], (x, y - 5), cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 0, 0), 1)      #include corresponding texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# showing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Result', img)            \n",
    "cv2.waitKey(0)\n",
    "if  ord('q'):\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
